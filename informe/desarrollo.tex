\subsection{Convenciones}
De aquí en adelante, si no se aclara otra cosa, se asumen las siguientes convenciones:
\begin{itemize}
\item$r_i$ es el radio que va del centro del horno al borde interno de la pared, mientras que $r_e$ es el radio considerando el borde externo;
\item$n$ es la cantidad de ángulos discretos ($0=\theta_0 <\hdots< \theta_{n-1} = 2\pi - \Delta \theta$) en los que se particiona la pared;
\item$m+1$ es el total de radios discretos ($~{r_i=r_0<\hdots<r_m=r_e}$); 
\item$t_{k,j} = T(r_k, \theta_j)$, donde $T$ es la función de temperatura de la pared (que desconocemos);
\item$b\in \mathbb{R}^{n\times (m+1)}: b = (b_0, b_1, \hdots, b_{(n\times (m+1))-1})$ será el vector de términos independientes del sistema que plantearemos luego (veremos que la dimensión escogida es correcta). 
\end{itemize}
\subsection{Métodos numéricos usados}
\label{sec:metodos}
A partir de la ecuación del calor de Laplace y las discretizaciones de las derivadas parciales dadas en el enunciado del presente trabajo práctico, se puede obtener un sistema de ecuaciones donde las soluciones son las temperaturas en los puntos de la discretización. 
Es decir que el problema de hallar la isoterma se reduce a dos sub-problemas: el primero es resolver efectivamente el sistema planteado, mientras que el segundo consiste en usar las temperaturas halladas para estimar la posición de la isoterma.\\
Para resolver el sistema haremos uso de los métodos de eliminación gaussiana y la factorización LU, para luego poder contrastar su eficiencia ante distintas situaciones. Adicionalmente, realizaremos una variación de cada método para aprovechar una de las características propias de la matriz del sistema.\\
Para hallar la posición de la isoterma (de temperatura $t_{iso}$), dado un ángulo $\theta_j$ de la discretización, lo que haremos es buscar dos radios, $r_k$ y $r_{k+1}$, tales que $t_{k+1,j} \leq t_{iso} \leq t_{k, j}$. A partir de estos dos valores, fácilmente podemos realizar un ajuste lineal considerando la recta de pendiente $m = \dfrac{t_{k,j}-t_{k+1,j}}{\Delta r}$ que pasa por $(r_k,t_{k,j})$ y $(r_{k+1}, t_{k+1,j})$. Para una explicación más detallada ver el apéndice ?????.

  
\subsection{Armado del sistema de ecuaciones y su matriz asociada}
\label{sec:armado-sistema}
Tenemos un sistema con $n\times(m+1)$ incógnitas.

Primero contamos con $n$ variables, los $t_{0,j}$ con $j = 0,1,\hdots, n-1$ (es decir, las temperaturas interiores), cuyos valores conocemos pues nos son dados como inputs. Lo mismo sucede con $t_{m, j}$ para $j = 0,1,..., n-1$ (temperaturas externas).
Luego, para las temperaturas interiores sabemos gracias a la función de Laplace y a la discretización de las derivadas que vale 

$\dfrac{t_{k-1,j} - 2t_{k,j} + t_{k+1,j}}{(\Delta r)^2} 
+ \dfrac{1}{r_k} \times \dfrac{t_{k,j} - t_{k-1,j}}{\Delta r}
+ \dfrac{1}{r_{k}^2} \times \dfrac{t_{k,j-1} -2t_{k,j} + t_{k,j+1}}{(\Delta \theta)^2} = 0$\\

Reescribiendo convenientemente la ecuación de arriba nos queda que 

\begin{equation}
\label{eq:laplace-discreto}
\dfrac{r_k - \Delta r}{r_k (\Delta r)^2} t_{k-1, j} +
\dfrac{1}{r_k^2(\Delta \theta)^2} t_{k, j-1} +
\dfrac{r_k \Delta r (\Delta \theta)^2 - 2(\Delta r)^2}{r_k^2 (\Delta r)^2 (\Delta \theta)^2} t_{k,j} +
\dfrac{1}{r_k^2(\Delta \theta)^2} t_{k, j+1} +
\dfrac{1}{(\Delta r)^2} t_{k+1,j}  = 0
\end{equation}

Hay que distinguir dos casos bordes que deben tratarse un poco diferente: si $j = 0$ entonces en lugar de $t_{k, j-1}$ se usa $t_{k, n-1}$, mientras que si $j = n-1$ en lugar de $t_{k, j+1}$ va $t_{k, 0}$.

Vale destacar que si bien todos los coeficientes dependen de la distancia al centro del horno ($r_k$), ninguno lo hace respecto del ángulo concreto en que se encuentra el punto. Esto resulta muy razonable si tenemos en cuenta que el valor del ángulo depende exclusivamente del sistema de referencia escogido (dónde ubicamos el ángulo 0), mientras que dado un punto de la pared es lógico que su temperatura no dependa del sistema de referencia escogido para su medición.

Para facilitar la lectura, de ahora en adelante llamaremos a los coeficientes de la ecuación (\ref{eq:laplace-discreto}): 
\begin{itemize}
\item $a_k = \dfrac{r_k - \Delta r}{r_k (\Delta r)^2}$ 
\item $b_k = \dfrac{1}{r_k^2(\Delta \theta)^2}$ 
\item $c_k = \dfrac{r_k \Delta r (\Delta \theta)^2 - 2(\Delta r)^2}{r_k^2 (\Delta r)^2 (\Delta \theta)^2}$ 
\item $d_k = \dfrac{1}{(\Delta r)^2}$
\end{itemize}

Pensamos ahora el orden que le daremos a los puntos de la discretización. Este será el orden en el que escribiremos las ecuaciones. Sin demasiadas complicaciones, un orden razonable es primero por ángulo (desde $\theta_0$ y avanzando en sentido antihorario) y luego por radio (de menor a mayor) respetando el orden relativo previo. Luego, dado un $t_{k,j}$ para obtener su posición (contada desde 0) en este orden debemos realizar la siguiente cuenta
\begin{equation}
\label{eq:posicion}
	posicion(t_{k,j}) = k\times n + j
\end{equation}

La cantidad total de variables es $n\times(m+1)$ (cantidad de ángulos por cantidad de radios), y como para cada una podemos o bien plantear la ecuación \ref{eq:laplace-discreto}, o bien ya conocemos su valor, podemos armar un sistema de $n\times(m+1)$ ecuaciones lineales.

A continuación presentamos el sistema de ecuaciones: 

\begin{equation}
\label{eq:sisecu}
  \left\lbrace
  \begin{array}{l}
     t_{0,0} = b_0 \\
     t_{0,1} = b_1 \\
     \vdots\\
     t_{0,n-1} = b_{n-1} \\
		 a_1 t_{0,0} + c_1 t_{1,0} + b_1 t_{1, 1} + b_1 t_{1, n-1} + d_1 t_{2, 0} = 0 = b_{n}\\
		 a_1 t_{0,1} + b_1 t_{1, 0} + c_1 t_{1,1} + b_1 t_{1,2} + d_1 t_{2,1} = 0 = b_{n+1} \\
		 \vdots\\
		 a_1 t_{0,n-2} + b_1 t_{1, n-3} + c_1 t_{1,n-2} + b_1 t_{1,n-1} + d_1 t_{2,n-1} = 0 = b_{2(n-1)} \\
		 a_1 t_{0,n-1} + b_1 t_{1, 0} + b_1 t_{1, n-2} + c_1 t_{1,n-1} + d_1 t_{2, n-1} = 0= b_{2n - 1}\\
		 a_2 t_{1,0} + c_2 t_{2,0} + b_2 t_{2, 1} + b_2 t_{2, n-1}  + d_2 t_{3, 0} = 0 = b_{2n}\\

		 a_{m-1} t_{m-2,n-1} + b_{m-1} t_{m-1,n-1} + c_{m-1} t_{m, n-1} + d_{m-1} t_{m-1, n-2} + d_{m-1} t_{m-1, 0} = 0 = b_{n\times m -1}\\
		 t_{m,0} = b_{n\times m}\\
		 \vdots\\
		 t_{m, n-1} = b_{n\times (m+1)-1}
		 
  \end{array}
  \right.
\end{equation}

$b$ tiene valores pasados por el usuario en las primeras $n$ posiciones y en las $n$ últimas, siendo el resto todos ceros.

Como primera observación importante notemos que el valor de cada $t_{k,j}$ ($1\leq k < m$) depende exclusivamente del valor de sus cuatro vecinos, lo que permite prever que cada fila de la matriz asociada tendrá sólo cinco elementos distintos de 0.

Para realizar la siguiente observación primero veamos un ejemplo concreto. Consideremos la siguiente discretización con $n = 4$ (particionamos la pared en cuatro ángulos iguales) y $m = 3$ (4 radios en total). El sistema tendrá entonces $4\times (3+1) = 16$ variables, con 16 ecuaciones. En este caso, el sistema (\ref{eq:sisecu}) queda así

\begin{equation}
\label{ej16x16}
  \left\lbrace
  \begin{array}{l}
     t_{0,0} = b_0 \\
     t_{0,1} = b_1 \\
     t_{0,2} = b_2 \\
     t_{0,3} = b_3 \\
		 a_1 t_{0,0} + c_1 t_{1,0} + b_1 t_{1, 1} + b_1 t_{1, 3} + d_1 t_{2,0} 		= 0 = b_{4}	\\
		 a_1 t_{0,1} + b_1 t_{1,0} + c_1 t_{1,1} + b_1 t_{1,2} + d_1 t_{2,1} 		 	= 0 = b_{5}	\\
	   a_1 t_{0,2} + b_1 t_{1,1} + c_1 t_{1,2} + b_1 t_{1,3} + d_1 t_{2,2} 			= 0 = b_{6}	\\
		 a_1 t_{0,3} + b_1 t_{1,0} + b_1 t_{1,2} + c_1 t_{1,3} + d_1 t_{2,3} 			= 0 = b_{7}	\\
		 a_2 t_{1,0} + c_2 t_{2,0} + b_2 t_{2,1} + b_2 t_{2,3} + d_2 t_{3,0}			= 0 = b_{8}	\\
		 a_2 t_{1,1} + b_2 t_{2,0} + c_2 t_{2,1} + b_2 t_{2,2} + d_2 t_{3,1} 		 	= 0 = b_{9}	\\
	   a_2 t_{1,2} + b_2 t_{2,1} + c_2 t_{2,2} + b_2 t_{2,3} + d_2 t_{3,2} 			= 0 = b_{10}	\\
		 a_2 t_{1,3} + b_2 t_{2,0} + b_2 t_{2,2} + c_2 t_{2,3} + d_2 t_{3,3} 			= 0 = b_{11}	\\
     t_{3,0} = b_{12} \\
     t_{3,1} = b_{13} \\
     t_{3,2} = b_{14} \\
     t_{3,3} = b_{15}     		 
  \end{array}
  \right.
\end{equation}

Ahora escribamos la matriz asociada a (\ref{ej16x16}) es \vspace{1em}

\setcounter{MaxMatrixCols}{16}
\begin{center}
$ A =
\begin{pmatrix}
	1	 	& 0 		& 0 		& 	0	 	& 0	 	& 0 		& 0	 	& 	0 		& 0		& 0 		& 0 		& 	0	  & 0		& 0	 	& 0 		& 	0\\
	0	 	& 1 		& 0 		& 	0	 	& 0 		& 0		& 0	 	& 	0 		& 0 		& 0 		& 0 		& 	0	  & 0 		& 0	 	& 0 		& 	0\\
	0	 	& 0 		& 1 		& 	0	 	& 0 		& 0 		& 0	 	& 	0 		& 0 		& 0 		& 0 		& 	0	  & 0 		& 0	 	& 0 		& 	0\\
	0 		& 0 		& 0 		& 1	 	& 0 		& 0 		& 0	 	& 	0 		& 0 		& 0 		& 0 		& 	0	  & 0 		& 0	 	& 0 		& 	0\\
	a_1 & 0 		& 0		& 0	 	& c_1 	& b_1 & 0		& b_1 & d_1 	& 0 		& 0 		& 	0	  & 0 		& 0	 	& 0 		& 	0\\
	0 		& a_1	& 0		& 0	 	& b_1 	& c_1 & b_1 	& 0 		& 0 		& d_1 	& 0 		& 	0	  & 0 		& 0	 	& 0 		& 	0\\
	0 		& 	0		& a_1	& 0	 	& 0		& b_1 	& c_1 & b_1 	& 0 		& 0 		& d_1 	& 0 	  & 0		& 0 	 	& 0		& 0\\
	0	 	& 0 		& 0 		& a_1	& b_1	& 0 		& b_1 	& c_1	& 0		& 0 		& 0 		& d_1 & 0 		& 0	 	& 0 		& 	0\\
	0 		& 0	 	& 0 		& 	0		&	a_2 & 0 		& 0		& 0	 	& c_2 	& b_2 & 0		& b_2 & d_2 	& 0 		& 0 		& 	0\\
	0 		& 	0	  & 0 		& 0	 	& 0 		& a_2	& 0		& 0	 	& b_2 	& c_2 & b_2 	& 0 		& 0 		& d_2 	& 0		& 0\\
	0 		& 	0		& 0 	 	& 0		& 0		& 0 		& a_2	& 0	 	& 0		& b_2 	& c_2 & b_2 	& 0 		& 0 		& d_2 	& 0\\ 	 
	0	 	& 0 		& 0 		& 0 		& 0	 	& 0 		& 	0		& a_2	& b_2	& 0 		& b_2 	& c_2	& 0		& 0 		& 0 		& d_2\\
	0	 	& 0 		& 0 		& 	0	 	& 0	 	& 0 		& 0	 	& 	0 		& 0		& 0 		& 0 		& 	0	  & 1		& 0	 	& 0 		& 	0\\
	0	 	& 0 		& 0 		& 	0	 	& 0 		& 0		& 0	 	& 	0 		& 0 		& 0 		& 0 		& 	0	  & 0 		& 1	 	& 0 		& 	0\\
	0	 	& 0 		& 0 		& 	0	 	& 0 		& 0 		& 0	 	& 	0 		& 0 		& 0 		& 0 		& 	0	  & 0 		& 0	 	& 1 		& 	0\\
	0 		& 0 		& 0 		& 0	 	& 0 		& 0 		& 0	 	& 	0 		& 0 		& 0 		& 0 		& 	0	  & 0 		& 0	 	& 0 		& 	1
\end{pmatrix} 
$
\end{center}

Rápidamente notamos que $A$ cumple la propiedad de ser una matriz banda. No solo eso, sino que además el ancho de ambas bandas (superior e inferior) es igual a 4, lo que coincide con $n$.

Tratemos ahora de convencernos que esto no se debe a una característica particular del ejemplo y que vale en el caso general.
Por un lado está claro que tanto las primeras como las últimas $n$ filas van a tener 1's en la diagonal y 0's en el resto de las posiciones, pues esas son las temperaturas que conocemos \textit{a priori}. Por lo tanto, con estas filas no hay problema.

Para las filas de en medio analicemos la distancia (entiéndase \textit{cantidad de variables de distancia}) desde el elemento de la diagonal hasta el último elemento no nulo de la fila, tanto a izquierda como  a derecha. Viendo la ecuación (\ref{eq:laplace-discreto}) es fácil darse cuenta que la variable más alejada (con coeficiente no nulo) a izquierda de $t_{k,j}$ es $t_{k-1, j}$, mientras que a derecha es $t_{k+1, j}$. Ambas variables están a distancia $n$ de $t_{k,j}$, pues para llegar desde el punto $(r_k, \theta_j)$ a $(r_k-1, \theta_j)$ o $(r_k+1, \theta_j)$ es necesario dar una vuelta completa ($n$ ángulos discretos) en sentido horario o antihorario respectivamente. Por lo tanto cualquier coeficiente de la matriz asociada a más de distancia $n$ de la diagonal es nulo. Con esto ya nos aseguramos que la matriz es banda, cuyo ancho es como mucho $n$. Pero además como dijimos que los coeficientes que acompañan a $t_{k-1, j}$ y $t_{k+1, j}$ son no nulos (lo cual vale siempre pues efectivamente $a_k$ y $d_k$ nunca pueden ser 0\footnote{Efectivamente $a_k = 0 \Leftrightarrow r_k - \Delta r = 0$, pero como $r_k = r_i + k\times \Delta r$ la única forma de que esa resta sea 0 es que $r_i$ sea 0, lo cual no tiene sentido en el contexto del problema (sería pura pared).}), es cierto que el ancho de ambas bandas es exactamente $n$. 


\subsection{Estructuración del código}
Para el modelado del problema diseñamos dos módulos: Matriz y Sistema. 

\subsubsection{Matriz}
\paragraph{Representación interna}
La representación interna es realmente simple: un vector de vectores fila, y dos enteros, n\_ para la cantidad de filas y m\_ para la cantidad de columnas.

\paragraph{Interfaz}
La interfaz de Matriz provee las siguientes operaciones:\footnote{Cuando se escribe la aridad de la función la misma puede no coincidir con la notación usada en C++. Esto está bien pues lo único que se busca aquí es dar una orientación de lo que hace cada función y no código preciso.}

\begin{itemize}
	\item Matriz(\textbf{int} n, \textbf{int} m, \textbf{double} init): constructor de la matriz. n es la cantidad de filas y m la de columnas, mientras que init será el valor que tendrán inicialmente todos los elementos de la matriz.

	\item Otras operaciones usuales: un constructor por copia, una función para imprimir la matriz, funciones que devuelven la cantidad de filas y de columnas, y un operador que permite acceder a cada elemento de la matriz (se numera a partir de 0).

	\item \textbf{vector<double>} backward\_subst(\textbf{Matriz} A, \textbf{vector<double>} b): función que dada una matriz cuadrada triangular superior sin ceros en la diagonal y un vector de tamaño igual a la cantidad de columnas de la matriz, resuelve el sistema planteado mediante el algoritmo de \textit{backward substitution}.

	\item \textbf{vector<double>} forward\_subst(\textbf{Matriz} A, \textbf{vector<double>} b): análogo al anterior pero para matrices triangulares inferiores, resuelve el sistema usando \textit{forward substitution}.

	\item \textbf{vector<double>} gaussian\_elim(\textbf{Matriz} A, \textbf{vector<double>} b)

	\item \textbf{pair<Matriz *, Matriz *>} LU\_fact()
	
	\item \textbf{vector<double>} gaussian\_elim\_banda(\textbf{vector<double>} b, \textbf{int} ancho)
	
	\item \textbf{pair<Matriz *, Matriz *>} LU\_fact\_banda(\textbf{int} ancho)
\end{itemize}

\subsubsection{Sistema}
Sistema es un módulo que engloba todo lo relacionado al modelado.

\paragraph{Representación interna}
Se almacenan varios valores: la cantidad de radios y ángulos de la discretización ($m\_mas\_uno\_$ y $n\_$), y el radio interno, el externo, $\Delta r$ y $\Delta\theta$. Se guarda un puntero a la matriz asociada al sistema de ecuaciones, $A$. $bs$ es un vector cuyos elementos a su vez son vectores, uno por cada instancia del problema que el usuario haya pasado. En $soluciones$ se guardarán los vectores solución del sistema para cada instancia.
Adicionalmente, tenemos algunas funciones auxiliares: 

\begin{itemize}
	\item $col\_matriz$ que permite obtener dados $k,j$ la posición de la variable $t_{k,j}$ en el orden que les dimos (realizando la operación (\ref{eq:calor}));
	\item \textbf{double} $resolver\_isoterma$(\textbf{vector<double>} radios, \textbf{double} isoterma, \textbf{double} eps = 0.0001): $radios$ tiene la temperatura en cada radio sobre un ángulo fijo, $isoterma$ es el valor de la isoterma buscada, y $eps$ es un parámetro \textit{hardcodeado} que define el error que se tiene en cuenta para realizar una comparación en el caso extremo en que la isoterma buscada no se encuentre entre ningún par de radios, es decir, que el radio buscado es menor que $r_i$ o mayor que $r_e$). Por decisión, en estos casos devolvemos $r_i$ o $r_e$ según la temperatura interior sea mayor que la isoterma buscada o no respectivamente. Sino, lo que devolvemos es la distancia desde el centro del horno hasta el punto donde estimamos se encuentra la isoterma (usando el ajuste lineal explicado en sección (\ref{sec:metodos})).
	\item Tres funciones que nos dan 3 criterios para decidir si el sistema está en peligro o no, dado un vector que tiene la posición de la isoterma en cada ángulo: mediana, promedio y máximo. 
\end{itemize}

\paragraph{Interfaz}
La interfaz de Sistema provee las siguientes operaciones:\footnote{Cuando se escribe la aridad de la función la misma puede no coincidir con la notación usada en C++. Esto está bien pues lo único que se busca aquí es dar una orientación de lo que hace cada función y no código preciso.}

\begin{itemize}
	\item Sistema(\textbf{double} r\_i,
					\textbf{double} r\_e,
          \textbf{int} m\_mas\_uno,
          \textbf{int} n,
          \textbf{vector<vector<double$>$>} interiores,
          \textbf{vector<vector<double$>$>} exteriores)	:
  		constructor del sistema. Cada vector de interiores es una medición de las temperaturas interiores en una determinada instancia (la cual está dada por la posición de la medición en interiores). exteriores es análogo a interiores para las mediciones de temperaturas exteriores. En una primera etapa inicializa los atributos de tipo double. Luego, arma A y bs.
          
  \item \textbf{void} solve(\textbf{ofstream\&} f\_soluciones, \textbf{metodo} met):

  \item \textbf{void} isotermas(\textbf{ofstream\&} f\_isotermas, \textbf{double} isoterma):

\end{itemize}

\subsection{Experimentación}

Pasemos a detallar los métodos que usamos para la experimentación.

En cuanto a la experimentación en lo que concierne al comportamiento de los resultados del programa cuando se cambian las discretizaciones, podemos decir que tuvimos muchos intentos hasta obtener el resultado deseado. De hecho, la experimentación extensiva que realizamos nos perimitió detectar un pequeño bug del código que no se hacía notar en los tests de la cátedra.

Para evaluar el comportamiento de los resultados, diseñamos configuraciones de sistemas que varían lo más posible cuando se cambia la discretización, como se verá en los resultados y la discusión.

Para evaluar como cambian los resultados cuando se aumenta la granularidad con respecto a los ángulos, lo que hicimos fue simplemente hacer un sistema cuyas temperaturas exteriores sean todas iguales, excepto 3 o 4 que son mucho más altas y están juntas. En consecuencia, cuando se achique la granularidad, estos detalles se perderán y el sistema parecerá más estable de lo que en realidad es.

Para evaluar como varían los resultados cuando se aumenta la granularidad con respecto a los radios, lo que hicimos fue similar, solo que no hace falta tomar un sistema muy especial, dado que las diferencias se notan fácilmente.

En cuanto a la experimentación en lo que concierne a la comparación del tiempo que le toma resolver el problema a cada uno de los métodos, lo que hicimos fue crear sistemas de variada granularidad y calcular cuanto tiempo le tomaba al programa resolverlo (desde que la matriz del sistema se terminó de construir, hasta que se resolvió el problema para todos los $b$'s).

Los tests fueron planteados por separado para sistemas en los que se debe resolver un único $b$ y otros en los que se debe resolver múltiples $b$s. Además, comparamos las implementaciones de eliminación Gaussiana, factorización LU y sus respectivas implementaciones optimizadas.

Al principio realizamos únicos tests que no distinguían granularidad de ángulos y de radios, pero luego notamos que en nuestras implementaciones optimizadas, teóricamente, podían surgir diferencias entre un cambio en la granularidad de ángulos y otro en la de radios, cosa que luego verificamos empíricamente. Por esta razón, decidimos separar los tests de tiempos de único $b$ en 2, uno que varíe cantidad de radios y otro cantidad de ángulos.


Para esto, repetimos 50 veces cada corrida, 30 veces las que tardaban mas de 30 segundos y 15 las que tomaban más de un minuto, dado que la desviación standard es mucho menor (dado que la desviación se debe generalmente a cambios de contexto durante el runtime del programa, que para programas que corren poco tiempo varía mucho).

Elegimos este número dado que la desviación standard era lo suficientemente chica como para que el experimento fuera confiable, y al mismo tiempo que tardaran un tiempo razonable para permitirnos realizar muchos experimentos.

Los tiempos fueron tomados en una computadora que contaba con un procesador Intel Core i5-2450M @ 2.50GHz, con 8GB de memoria RAM.
