\subsection{Convenciones}
De aquí en adelante, si no se aclara otra cosa, se asumen las siguientes convenciones:
\begin{itemize}
\item$r_i$ es el radio que va del centro del horno al borde interno de la pared, mientras que $r_e$ es el radio considerando el borde externo;
\item$n$ es la cantidad de ángulos discretos ($0=\theta_0 <\hdots< \theta_{n-1} = 2\pi - \Delta \theta$) en los que se particiona la pared;
\item$m+1$ es el total de radios discretos ($~{r_i=r_0<\hdots<r_m=r_e}$); 
\item$t_{k,j} = T(r_k, \theta_j)$, donde $T$ es la función de temperatura de la pared (que desconocemos);
\item$b\in \mathbb{R}^{n\times (m+1)}: b = (b_0, b_1, \hdots, b_{(n\times (m+1))-1})$ será el vector de términos independientes del sistema que plantearemos luego (veremos que la dimensión escogida es correcta). 
\end{itemize}
\subsection{Métodos numéricos usados}
A partir de la ecuación del calor de Laplace y las discretizaciones de las derivadas parciales dadas en el enunciado del presente trabajo práctico, se puede obtener un sistema de ecuaciones donde las soluciones son las temperaturas en los puntos de la discretización. 
Es decir que el problema de hallar la isoterma se reduce a dos sub-problemas: el primero es resolver efectivamente el sistema planteado, mientras que el segundo consiste en usar las temperaturas halladas para estimar la posición de la isoterma.\\
Para resolver el sistema haremos uso de los métodos de eliminación gaussiana y la factorización LU, para luego poder contrastar su eficiencia ante distintas situaciones.\\
Para hallar la posición de la isoterma (de temperatura $t_{iso}$), dado un ángulo $\theta_j$ de la discretización, lo que haremos es buscar dos radios, $r_k$ y $r_{k+1}$, tales que $t_{k+1,j} \leq t_{iso} \leq t_{k, j}$. A partir de estos dos valores, facilmente podemos realizar un ajuste lineal considerando la recta de pendiente $m = \dfrac{t_{k,j}-t_{k+1,j}}{\Delta r}$ que pasa por $(r_k,t_{k,j})$ y $(r_{k+1}, t_{k+1,j})$. Para una explicación más detallada ver el apéndice ?????.

  
\subsection{Armado del sistema de ecuaciones y su matriz asociada}
Tenemos un sistema con $n\times(m+1)$ incógnitas.

Primero contamos con $n$ variables, los $t_{0,j}$ con $j = 0,1,\hdots, n-1$ (es decir, las temperaturas interiores), cuyos valores conocemos pues nos son dados como inputs. Lo mismo sucede con $t_{m, j}$ para $j = 0,1,..., n-1$ (temperaturas externas).
Luego, para las temperaturas interiores sabemos gracias a la función de Laplace y a la discretización de las derivadas que vale \\

$\dfrac{t_{k-1,j} - 2t_{k,j} + t_{k+1,j}}{(\Delta r)^2} 
+ \dfrac{1}{r_k} \times \dfrac{t_{k,j} - t_{k-1,j}}{\Delta r}
+ \dfrac{1}{r_{k}^2} \times \dfrac{t_{k,j-1} -2t_{k,j} + t_{k,j+1}}{(\Delta \theta)^2} = 0$\\

Reescribiendo convenientemente la ecuación de arriba nos queda que \\

\begin{equation}
\label{laplace}
\dfrac{r_k - \Delta r}{r_k (\Delta r)^2} t_{k-1, j} +
\dfrac{1}{r_k^2(\Delta \theta)^2} t_{k, j-1} +
\dfrac{r_k \Delta r (\Delta \theta)^2 - 2(\Delta r)^2}{r_k^2 (\Delta r)^2 (\Delta \theta)^2} t_{k,j} +
\dfrac{1}{r_k^2(\Delta \theta)^2} t_{k, j+1} +
\dfrac{1}{(\Delta r)^2} t_{k+1,j}  = 0
\end{equation}

Vale destacar que si $j = 0$ entonces en lugar de $t_{k, j-1}$ se usa $t_{k, n-1}$, mientras que si $j = n-1$ en lugar de $t_{k, j+1}$ va $t_{k, 0}$.

De esto se desprende inmediatamente que el valor de cada $t_{k,j}$ ($1\leq k < m$) depende exclusivamente de sus cuatro vecinos. Cabe mencionar también que si bien todos los coeficientes dependen de la distancia al centro del horno ($r_k$), ninguno lo hace respecto del ángulo concreto en que se encuentra el punto. Esto resulta muy razonable si tenemos en cuenta que el valor del ángulo depende exclusivamente del sistema de referencia escogido (dónde ubicamos el ángulo 0), mientras que dado un punto de la pared es lógico que su temperatura no dependa del sistema de referencia escogido para su medición.

Para facilitar la lectura, de ahora en adelante llamaremos a los coeficientes de la ecuación (\ref{laplace}) (respetando el orden en que aparecen): $a_k$ (el coeficiente que acompaña a $t_{k-1, j}$), $b_k$ (el coeficiente que acompaña a $t_{k, j-1}$ y $t_{k, j+1}$), $c_k$, $d_k$ . Notar que por la observación anterior estos coeficientes sólo dependen del radio.

Pensamos ahora el orden que le daremos a los puntos de la discretización. Este será el orden en el que escribiremos las ecuaciones. Sin demasiadas complicaciones, un orden razonable es primero por ángulo (desde $\theta_0$ y avanzando en sentido antihorario) y luego por radio (de menor a mayor) respetando el orden relativo previo.

A continuación presentamos el sistema de ecuaciones formado 

\begin{equation}
\label{sisecu}
  \left\lbrace
  \begin{array}{l}
     t_{0,0} = b_0 \\
     t_{0,1} = b_1 \\
     \vdots\\
     t_{0,n-1} = b_{n-1} \\
		 a_1 t_{0,0} + c_1 t_{1,0} + b_1 t_{1, 1} + b_1 t_{1, n-1} + d_1 t_{2, 0} = 0 = b_{n}\\
		 a_1 t_{0,1} + b_1 t_{1, 0} + c_1 t_{1,1} + b_1 t_{1,2} + d_1 t_{2,1} = 0 = b_{n+1} \\
		 \vdots\\
		 a_1 t_{0,n-2} + b_1 t_{1, n-3} + c_1 t_{1,n-2} + b_1 t_{1,n-1} + d_1 t_{2,n-1} = 0 = b_{2(n-1)} \\
		 a_1 t_{0,n-1} + c_1 t_{1,n-1} + b_1 t_{1, 0} + b_1 t_{1, n-2} + d_1 t_{2, n-1} = 0= b_{2n - 1}\\
		 a_2 t_{1,0} + b_2 t_{2,0} + c_2 t_{3, 0} + d_2 t_{2, n-1} + d_2 t_{2, 1} = 0 = b_{2n}\\
		 \vdots\\
		 a_{m-1} t_{m-2,n-1} + b_{m-1} t_{m-1,n-1} + c_{m-1} t_{m, n-1} + d_{m-1} t_{m-1, n-2} + d_{m-1} t_{m-1, 0} = 0 = b_{n\times m -1}\\
		 t_{m,0} = b_{n\times m}\\
		 \vdots\\
		 t_{m, n-1} = b_{n\times (m+1)-1}
		 
  \end{array}
  \right.
\end{equation}

$b$ tiene valores pasados por el ususario en las primeras $n$ posiciones y en las $n$ últimas, siendo el resto todos ceros.




\subsection{Estructuración del código}
Para el modelado del problema diseñamos dos módulos: Matriz y Sistema. 

El primero provee una representación para matrices con una interfaz conveniente. Utilizamos como representación interna un vector de vectores, junto con la cantidad de filas y columnas de la matriz. Las operaciones de Matriz permiten, dado un vector de términos independientes, obtener la solución de un sistema triangular superior sin ceros en la diagonal (o triangular inferior sin ceros en la diagonal) mediante \textit{backward substitution} (respectivamente \textit{forward substitution}), realizar eliminación gaussiana sin pivoteo (en caso de que sea posible), y, de existir, obtener la factorización LU de una matriz. Adicionalmente, hicimos otras versiones de eliminación gaussiana y factorización LU que requieren que la matriz en la que se aplican sea banda, y aprovechan este hecho para reducir la cantidad de operaciones básicas a realizar.\\

\subsection{Experimentación}

Pasemos a detallar los metodos que usamos para la experimentación.



En cuanto a la experimentación en lo que concierne al comportamiento de los resultados del programa cuando se cambian las discretizaciones, podemos decir que tuvimos muchos intentos hasta obtener el resultado deseado. De hecho, la experimentación extensiva que realizamos nos perimitió detectar un pequeño bug del código que no se hacia notar en los tests de la cátedra.

Para evaluar el comportamiento de los resultados, diseñamos configuraciones de sistemas que varíen lo más posible cuando se cambiara la discretización, como se verá en los resultados y la discusión.

Para evaluar como varían los resultados cuando se aumenta la granularidad con respecto a los ángulos, lo que hicimos fue simplemente hacer un sistema cuyas temperaturas exteriores sean todas iguales, excepto 3 o 4 que son mucho más altas y están juntas. En consecuencia, cuando se achique la granularidad, estos detalles se perderán y el sistema parecerá más estable de lo que en realidad es.

Para evaluar como varían los resultados cuando se aumenta la granularidad con respecto a los radios, lo que hicimos fue similar, solo que no hace falta tomar un sistema muy especial, dado que las diferencias se notan fácilmente.



En cuanto a la experimentación en lo que concierne a la comparación del tiempo que le toma resolver el problema a cada uno de los metodos, lo que hicimos fue crear sistemas de variada granularidad y calcular cuanto tiempo le tomaba al programa resolverlo, (desde que la matriz del sistema se terminó de construir, hasta que se resolvió el problema para todos los $b$'s).

Los tests fueron planteados por separado para sistemas en los que se debe resolver un único $b$ y otros en los que se debe resolver múltiples $b$s. Además, comparamos las implementaciones de eliminación Gaussiana, factorización LU y sus respectivas implementaciones optimizadas.

Al principio realizamos únicos tests que no distiniguían granularidad de ángulos y de radios, pero luego notamos que en nuestras implementaciones optimizadas, teóricamente, iba a ser importante diferenciar entre granularidad de ángulos y de radios, lo que finalmente sucedió. Por esta razón, decidimos separar los tests de tiempos de único $b$ en 2, uno que varíe cantidad de radios y otro cantidad de ángulos.


Para esto, repetimos 50 veces cada corrida, 30 veces las que tardaban mas de 30 segundos y 15 las que tomaban más de un minuto, dado que la desviación standard es mucho menor (dado que la desviación se debe generalmente a cambios de contexto durante el runtime del programa, que para programas que corren poco tiempo varía mucho).

Elegimos este número dado que la desviación standard era lo suficientemente chica como para que el experimento fuera confiable, y al mismo tiempo que tardaran un tiempo razonable para permitiernos realizar muchos experimentos.

Los tiempos fueron tomados en una computadora que con un procesador Intel Core i5-2450M @ 2.50GHz, con 8GB de memoria RAM.